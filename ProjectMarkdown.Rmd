---
title: "ISA 616 Class Project RMarkdown"
author: 
  - Yao Luo
date: "`r format(Sys.Date(), '%B %d, %Y')`"
bibliography: refs.bib
output: 
  html_document:
    code_folding: show
    df_print: paged
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache=TRUE,
                      out.width="100%",
                      warning=FALSE,
                      message=FALSE,
                      clean_cache=TRUE)
```

# Introduction

This article aims to provide a reproducible analytics workflow solving a hypothetical business problem using a predictive regression model on the UCI Wine data. A hypothetical business value proposition along with the full analytics solution will be provided. The important processes will also be documented. You can access teh source code in my GitHub account here: https://github.com/luoy25/ISA616Project.git

## Data Background

The datasets used is obtained from UCI Machine Learning Repository. The two datasets are related to red and white variants of the Portuguese "Vinho Verde" wine. For more details, consult: https://www.vinhoverde.pt/en/ 

## Business Problem

The business background of the project is to provide an analytics solution to the sales team in assisting with predicting wine quality / expert rating using only its chemical feature. The sales team would like to estimate on the wine quality before being in an expert so that they can potentially reduce cost by only have the expert rate the wine that's estimated to have higher quality. 

## Business Value Proposition

![](BusinessValueProposition.png)

# Data Overview

## Source of Data

Paulo Cortez, University of Minho, Guimar√£es, Portugal, http://www3.dsi.uminho.pt/pcortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis, Viticulture Commission of the Vinho Verde Region(CVRVV), Porto, Portugal, 2009

Download red wine dataset: <https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv>

Download white wine dataset: <https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv>

## Dataset Description

The datasets include 12 variables: 

Input variables: 

 * fixed.acidity
 * volatile.acidity
 * citric.acid
 * residual.sugar
 * chlorides
 * free.sulfur.dioxide
 * density
 * pH
 * sulphates
 * alcohol
 * quality

Output Variable:

 * wine.type (Score between 0 and 10)

For more information, read from this file: <https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality.names>

## A Glimps of Data {.tabset .tabset-fade .tabset-pills}

There are 12 columns available in both datasets. We can see that both datasets have the same attributes with the same data type, therefore it is reasonable for them to be combined.

```{r}
wineRed = read.csv("winequality-red.csv",sep = ";")
wineWhite = read.csv("winequality-white.csv",sep = ";")
```

### RedWine {-}

```{r}
head(wineRed)
```

### RedWine Structure{-}

```{r}
str(wineRed)
```

### WhiteWine {-}

```{r}
head(wineWhite)
```

### WhiteWine Structure{-}

```{r}
str(wineWhite)
```


# Data Preprocessing

Before we work on preparing the data, we need to load the needed libraries and also create functions(if needed) for further analysis. 

```{r}
# Load required packages
if(require(pacman)==FALSE) 
  install.packages("pacman")
pacman::p_load(tidyverse,hexbin,caret,car,DataExplorer,kableExtra,MLmetrics)
```

```{r}
# Create Metadata Function
Metadata<-function(df){
  library(DataExplorer)
  library(kableExtra)
  z<-introduce(df)
  z<-as.data.frame(t(z))
  colnames(z)<-c()
  knitr::kable(
    z,
    caption="Data Introduction"
  ) %>% kable_styling(bootstrap_options = c("striped", "hover"),
                      full_width = F,
                      font_size = 12,
                      position = "left")
  
}

# Create Model Evaluation Function
Evaluation <- function(model, y_pred, y_true) {
  library(MLmetrics)
  adjr2 <- summary(model)$adj.r.squared
  mse <- MSE(y_pred, y_true)
  rmse <- RMSE(y_pred, y_true)
  mae <- MAE(y_pred, y_true)
  print(paste0("Adjusted R-squared: ", round(adjr2, 4)))
  print(paste0("MSE: ", round(mse, 4)))
  print(paste0("RMSE: ", round(rmse, 4)))
  print(paste0("MAE: ", round(mae, 4)))
}
```

## Missing Data

Based on the output below, we can see that there are no missing data present in both red and white wine datasets. 


```{r}
library(tidyverse)
wineRed %>% is.na() %>% colSums()
wineWhite %>% is.na() %>% colSums()
```

## Merging Datasets {.tabset .tabset-fade .tabset-pills}

We learned earlier that both datasets has same attributes so it makes sense for us to combine them. The different wine types are transformed into dummies and stored in a categorical variable named wine.type. 

```{r}
# Create Dummies
wineRed$wine.type <- 1
wineWhite$wine.type <- 0

# Check Dimensions
dim(wineRed)
dim(wineWhite)

# Combine dataframes
wine = rbind(wineRed, wineWhite)

# Recode attribute as factor
wine$wine.type <- as.factor(wine$wine.type)

# Double check dimension
dim(wine)
```

### MetaData For Red Wine {-}

```{r echo=FALSE}
source("Functions.R")
Metadata(wineRed)
```

### MetaData For White Wine {-}

```{r echo=FALSE}
source("Functions.R")
Metadata(wineWhite)
```

### MetaData For Wine {-}

```{r echo=FALSE}
source("Functions.R")
Metadata(wine)
```


# Explanatory Data Analysis

To explore the dataset, we can take a look at a scatterplot for the response. We will use histograms for numerical variables, bar chart for categorical variables. Some  other summarized statistics were also shown down below. 

## Dataset Summary {.tabset .tabset-fade .tabset-pills}

From the scatterplot, we cannot see any obvious trend between any variables and response. 

From the histogram, we can see that most numeric variables are right skewed and unimodel which makes sense as these variables can't have negative values. PH and quality are both normally distributed. Total sulfur dioxide seems to be bimodel.

The barplot shows the distribution of red and white wine with more white wine in the data. 

### Head of Wine {-}

```{r}
head(wine)
```

### Scatterplot {-}

```{r}
## Scatterplot `quality` with all other continuous features
plot_scatterplot(split_columns(wine)$continuous, by = "quality", sampled_rows = 1000L)
```

### Histograms {-}

```{r}
library(DataExplorer)
plot_histogram(wine)
```

### Bar Plot {-}

```{r}
library(DataExplorer)
plot_bar(wine)
```

### Statistical Summary {-}

```{r}
summary(wine)
```

### Data Structure {-}

```{r}
str(wine)
```

## Correlation & Multicolinearity

### Correlation Plot

```{r}
library(DataExplorer)
plot_correlation(wine, type = "c")
```

### Strong Correlations

Based on the correlation plot above, some of the predictors have strong correlations: 

 * Between density and alcohol (-0.69)
 * Between free.sulfur.dioxide and total.sulfur.dioxide (0.72)

These strongly correlated variable could potentially lead to multicolinearity. 

# Modeling

## Spliting Data

To build the model, I will split it up the dataset into 75% of data for train datasets and 25% of data for test datasets.

```{r}
set.seed(13)
trainIndex = sample(1:nrow(wine), size = round(0.75*nrow(wine)), replace=FALSE)
train<-wine[trainIndex, ]
valid<-wine[-trainIndex, ]
nrow(train)
nrow(valid)
```

## Stepwise Model

We will feed all predictors to create a full model, and then run a stepwise model from both directions. I have eliminated the summary for full model and show the summary for the final stepwise model down below. 

```{r}
library(MASS)
options(scipen=999)
# Fit the full model 
full <- lm(quality ~., data = train)
# Stepwise regression model
step <- stepAIC(full, direction = "both", trace = FALSE)
summary(step)
```

# Results and Performance

The final stepwise model consists of the following equation: 

$\hat{Y} = \hat{\beta_0} + \hat{\beta_1}x_1+\hat{\beta_2}x_2+\hat{\beta_3}x_3+\hat{\beta_4}x_4+\hat{\beta_5}x_5+\hat{\beta_6}x_6+\hat{\beta_7}x_7+\hat{\beta_8}x_8+\hat{\beta_9}x_9+\hat{\beta_{10}}x_{10}$

where the following are values form the $\hat{\beta_0}$ to $\hat{\beta_{10}}$ and from $x_1$ to $x_{10}$: 

```{r}
step$coefficients
```

## Model Interpretation

Based on the equation, we can interpret  $\hat{\beta_0}$ as the Y-Intercept of the line. Meaning that when all chemicals have a value of 0, the quality of the wine on average is 117.8048. It is not realistic as the rating only ranges from 0 to 10. As for other $\hat{\beta}$s, we can interpret them as when there is an increase of any in $x_i$, the corresponding $\hat{\beta_i}$ will adjust according to the value. 

As an example, to interpret the intercept of pH, we can say that when there is a 1 unit increase in $x_{pH}$, on average, there will be a 0.6013 unit increase in the quality of the wine, holding all other variables constant. 

## Predicitons

Although we can interpret the model this way, the main goal of this model is to predict the quality of wine based on its chemical features, and therefore we would like to make some predictions using the model. The predicitons will be made on both training and validation data so that we can use them for evaluation. 

### Using training data

```{r}
p.train<-predict(step, newdata=train)
head(p.train)
```

### Using validaiton data

```{r}
p.valid<-predict(step, newdata=valid)
head(p.valid)
```

## Model Evaluation

To evaluate the model performance, we are using the pre-written function to provide us with some of the useful metrics. Although we are more interested in the predictions made on the validation data, we want to compare there numbers between the training and validation data to prevent overfitting. The metrics used are: Mean Squared Error (MSE), Root Mean Squared Error(RMSE), Mean Absolute Error(MAE) and adjusted R-squared. 

### Evaluation on training data

```{r}
source("Functions.R")
Evaluation(step, p.train, train$quality)
```

### Evaluation on validation data

```{r}
source("Functions.R")
Evaluation(step, p.valid, valid$quality)
```

As we can see from the results above, there seems to be no overfitting issues as the results for training data is similar to that of validation data. The model seemed to even performed slightly better on the validation dataset as we have a slightly lower RMSE of 0.7319 compared to 0.7334. We have an adjusted R-squared of 0.2977 meaning that on average 29.77% of the variation can be explained by the model. 

## Business Implications

### Limitation in data

```{r}
plot_histogram(wine$quality)
```

From the histogram, we can see that the majority of the data falls into the middle range of the quality scale. This is not very helpful in our model building as we are interested in learning what makes a wine being ranked very low or high and there are not enough data that we have on hand to teach the model what a really bad wine is like. To improve that, we can collect more wine data especially the ones that has low ratings or high ratings. Conducting a model on a dataset with a balanced quality scale would possible help with improving the model performance. 

### Limitation on wine rating process itself

Imagine we collected more data like mentioned above and realized that the model was not improved much, and is still not powerful in predicting the wine quality, we need to start thinking about the wine rating process itself. This means that the data we currently have on hand can only provide us with this much information and we can't do any better by adjusting the model. We need to look into the wine rating process and find out what are the other factors that impacts the ratings of wine. A possible solution is to observe the rating process of a wine rating expert. Some levels of interviews may also be conducted to find out why they rate the wine the way it is. Perhaps it is factors like the smell of the wine, or the color of the liquid, or even whether there are bitterness in the taste. Once more important factors has been found, we need to collect such data on the wine being rated and start building new models on these newly collected data. 

### Current Model

Let's say that we can not collect more data and that we also cannot find a wine expert who is willing to explain the impact factors to us, we will have to use our current model to meet our objective. Although the model performs poorly based on its prediction power, depending on the end goal and our criteria, we can effectively use this model regardless of its poor performance. 
Let's take a look at the model performance

#### Performance Evaluation {.tabset .tabset-fade .tabset-pills}

##### In sample Performance {-}
```{r}
train$pred_quality=step$fitted.values

p=ggplot(data = train)+
  geom_point(aes(quality,pred_quality,col="blue"),size=1,data=train)
p=p+xlim(2,10)+ylim(2,10)
p=p+labs(x="Actual Quality",y="Predicted Quality")+ggtitle("In sample performance")
p=p+scale_color_manual(labels = c("Stepwise Model"),values = c("blue"))
p=p+geom_abline(slope = 1,intercept = 0)
p
```

##### Out of sample Performance {-}
```{r}
valid$pred_quality=predict(step, newdata=valid)

p = ggplot(data = valid)+
  geom_point(aes(quality,pred_quality,col="red"),size=1)
p=p+xlim(2,10)+ylim(2,10)
p=p+labs(x="Actual Quality",y="Predicted Quality")+ggtitle("Out of Sample performance")
p=p+scale_color_manual(labels = c("Stepwise Model"),values = c("red"))
p=p+geom_abline(slope = 1,intercept = 0)
p
```
#### Recommendations

Based on the in sample performance graphic, we can see that the model prediction is not well matched with the actual quality. To be more specific, we can see that the prediction on lower grade wine tends to be relatively high while the predictions for higher grade wine tends to be relatively low. And that is the main reason our overall prediction is way off the expectation. As mentioned earlier, this could be happening due to the lack of data on lower and higher grade wine. However, this current model can be used effectively based on our business objective and our criteria.

Our overall goal is to reduce the amount of wine rated so that the cost of bringing in experts can be reduced. However, we need to be relatively conservation and not eliminate any wine that are actually high quality wine. The model can help us select the wine to be eliminated for all the predicted values being 5 or lower. Because based on the performance result, we can see that all the value predicted to be lower than 5 is in reality lower than 7. Depending on the criteria of the business, we can change the threshold of elimination as long as we made sure it is lower than 5 because once the predicted value hits 6, some of the actual high quality wine will be eliminated. The only down side is that a lot of low quality wine will still be rated higher than 5 and we will end up bring in experts for them making it a bit more costly. However, we are still reducing the cost from rating all wine to cutting out a small portion of fairly low quality wine to not be rated. 

Just to make sure this pattern is reasonable, we can double check on the out of sample data to ensure its performance. We can see that all wine that has a predicted score of 5 or below has in reality, a quality less than 6. Although we weren't able to eliminate the very low rated wine, the model is helpful to ensure that we are not eliminating any high quality wine to be rated. 

# Conclusion

## Project Results

To conclude from this project, here are some of the main points covered: 

 * A linear stepwise model has been created. The target variable is quality, whereas the predictors used were attributes of physicochemical tests.
 * The final stepwise model equation is as following, see interpretations from the Results and Performance Section: 
 $\hat{Y} = \hat{\beta_0} + \hat{\beta_1}x_1+\hat{\beta_2}x_2+\hat{\beta_3}x_3+\hat{\beta_4}x_4+\hat{\beta_5}x_5+\hat{\beta_6}x_6+\hat{\beta_7}x_7+\hat{\beta_8}x_8+\hat{\beta_9}x_9+\hat{\beta_{10}}x_{10}$
 * The model was evaluated using MSE, RMSE, ASE, and Adjusted R-Squared.

## Business Value

To reflect on the business purpose and value proposition: 
 
 * We are able to use this model to predict wine quality using its physicochemical features with a 29.77 % of the variation being explained by the model.
 * Tho the model performance is not ideal, it is still an improvement with solving the given business problem. It is also important to note that it is hard to improve the performance of the model as we see almost no correlation between the predictors and target from the scatterplots. 
 * The sales team of the wine company can use this model to have a rough estimation of their new wine's quality before actually bring in an expert. This may help with reducing costs from bringing in the wine experts for wine with extremely poor quality. 

## Reflection and Improvements

To reflect on the process, here are some related thoughts: 

 * Removing outliers were attempted but the model was not improved significantly and therefore it was eliminated from the report.
 * Version control was helpful as it helped with tracking progress and updates.
 * Further analysis can be conducted in the future by trying different model building methods, conducting a PCA for correlated variables and reducing dimensions, or implementing interaction terms. 

